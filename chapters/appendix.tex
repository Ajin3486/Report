\chapter{Detailed Experimental Settings}
\label{appendix:experimental_settings}

\section{PPO Hyperparameters \& Reward Function}

\begin{table}[h]
\centering
\caption{PPO Hyperparameters}
\label{tab:ppo_params}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Total Timesteps & 19,660,800 \\
Number of Environments & 4096 \\
Horizon (Steps per Episode) & 32 \\
Batch Size & 131,072 \\
Mini-batch Size & 32,768 \\
Number of Mini-batches & 4 \\
Number of Epochs & 5 \\
Clip Range ($\epsilon$) & 0.1 \\
Entropy Coefficient & $1 \times 10^{-4}$ \\
Value Function Coefficient & 1.0 \\
Learning Rate & $1 \times 10^{-4}$ (Adaptive) \\
Discount Factor ($\gamma$) & 0.99 \\
GAE ($\lambda$) & 0.95 \\
Max Iterations & 150 \\
\bottomrule
\end{tabular}
\end{table}

The total reward is: $r = r_{\text{track}} + r_{\text{guide}} - p_{\text{action}} - p_{\text{smooth}}$, where $r_{\text{track}} = 5.0 \cdot e^{-\|e_{\text{pos}}\|^2/0.02}$, $r_{\text{guide}} = 1.0 \cdot e^{-\|e_q\|^2/0.05}$, $p_{\text{action}} = 0.01\|\mathbf{a}\|^2$, and $p_{\text{smooth}} = 0.1\|\Delta\mathbf{a}\|^2$.

\noindent\textbf{Source Code:} \url{https://github.com/Lucavogel/sim2real-pnp}

\section{Source Code Repository}
The full source code, training scripts, ROS 2 packages, and experimental data for this project are publicly available at:
\begin{center}
    \url{https://github.com/Lucavogel/sim2real-pnp}
\end{center}
The repository includes the Isaac Lab training environment, the ROS 2/MoveIt integration, the PPO policy checkpoints, and the dataset generation scripts.



