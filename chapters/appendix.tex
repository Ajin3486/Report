\chapter*{Appendix}
\addcontentsline{toc}{chapter}{Appendix}
\label{appendix:experimental_settings}

This appendix provides supplementary technical details to ensure reproducibility of the results presented in this work.

\medskip
\noindent\textbf{PPO Training Hyperparameters.}
Table~\ref{tab:ppo_params} reports the complete set of hyperparameters used to train the PPO policy in Isaac Lab. These values were selected based on standard baselines for continuous robotic control tasks and kept fixed throughout all experiments.

\begin{table}[h]
\centering
\caption{PPO Hyperparameters used for Isaac Lab training.}
\label{tab:ppo_params}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Total Timesteps & 19,660,800 \\
Number of Environments & 4096 \\
Horizon (Steps per Episode) & 32 \\
Batch Size & 131,072 \\
Mini-batch Size & 32,768 \\
Number of Mini-batches & 4 \\
Number of Epochs & 5 \\
Clip Range ($\epsilon$) & 0.1 \\
Entropy Coefficient & $1 \times 10^{-4}$ \\
Value Function Coefficient & 1.0 \\
Learning Rate & $1 \times 10^{-4}$ (Adaptive KL) \\
Discount Factor ($\gamma$) & 0.99 \\
GAE ($\lambda$) & 0.95 \\
Max Iterations & 150 \\
\bottomrule
\end{tabular}
\end{table}

\medskip
\noindent\textbf{Reward Function.}
The total reward at each timestep is defined as:
\begin{equation*}
r = \underbrace{5.0\, e^{-\|e_{\mathrm{pos}}\|^2/0.02}}_{\text{tracking}} + \underbrace{1.0\, e^{-\|e_q\|^2/0.05}}_{\text{guidance}} - \underbrace{0.01\,\|\mathbf{a}\|^2}_{\text{action penalty}} - \underbrace{0.1\,\|\Delta\mathbf{a}\|^2}_{\text{smoothness penalty}}
\end{equation*}
The exponential kernels provide dense, bounded gradients at every timestep, while the penalty terms encourage energy-efficient and smooth joint corrections.

\medskip
\noindent\textbf{Source Code.}
The complete implementation — including the Isaac Lab training environment, ROS\,2/MoveIt integration, PPO policy checkpoints, and dataset generation scripts — is publicly available at:\begin{center}\url{https://github.com/Lucavogel/sim2real-pnp}\end{center}



\section{Training Duration}
The PPO training run used for the reported results lasted approximately 10 hours.
According to the execution log, the elapsed training time was \textbf{10:09:11} (about 10 h).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/trainh.png}
    \caption{Training log snapshot showing an elapsed time of 10:09:11.}
    \label{fig:training_duration_log}
\end{figure}


