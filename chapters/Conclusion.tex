\section{Summary of Contributions}

This work delivered a complete residual RL pipeline for the UR10: ROS 2/MoveIt generates safe nominal trajectories, a PPO policy trained across 4096 parallel Isaac Lab environments learns corrective actions ($\pm 0.05$ rad/s), and multi-layer domain randomization (sensor noise, calibration offsets, action latency, dynamics perturbations) bridges the sim-to-real gap. The result is a 69.7\% reduction in mean tracking error (28.4\,mm $\rightarrow$ 8.6\,mm) with emergent compensation strategies — notably a systematic +0.63° bias on J4 to correct for camera calibration errors — confirming that classical planning and deep RL can be productively combined.

\section{Limitations and Lessons Learned}

\textbf{Sim-to-Sim Validation Only.} The current validation remains within Isaac Lab's PhysX engine. While domain randomization improves robustness, there is a risk that the policy exploited simulation-specific artifacts (numerical precision, simplified contact models, deterministic dynamics) that differ from physical reality. This represents the primary limitation of this work.

\textbf{Time Constraints.} The original objective was full sim-to-real transfer on the physical UR10. However, time limitations prevented extensive real-world testing. Deploying learned policies on physical systems requires careful safety protocols, failure recovery mechanisms, and iterative tuning—processes that demand significant experimentation time beyond the scope of this project.

\textbf{Calibration Dependency.} Although the policy is trained to handle calibration errors up to $\pm 2$cm, deployment success depends critically on initial calibration quality. If real-world errors exceed the training distribution, performance degradation is expected. This highlights the importance of good initial calibration even when using adaptive controllers.

\section{Future Work and Perspectives}

If given additional time, several validation steps would strengthen confidence in real-world transferability:

\textbf{Sim-to-Sim Transfer: Isaac Lab $\rightarrow$ MuJoCo.} The immediate next step is evaluating the trained policy in a physically different simulator (MuJoCo) with distinct physics engines, contact solvers, and numerical integrators. Success in cross-simulator transfer would provide strong evidence that the policy learned generalizable control strategies rather than simulation-specific heuristics. MuJoCo's different friction model and more accurate contact dynamics would serve as an intermediate reality gap test before attempting real robot deployment.

\textbf{Physical Robot Deployment.} The ultimate objective is deployment on the physical UR10. This transition from simulation to reality represents the final validation step, where the policy would face true sensor noise, unmodeled dynamics, and real-world uncertainties that cannot be perfectly captured in simulation. Successful deployment would require careful safety protocols and progressive testing to ensure reliable operation.

\textbf{Extended Scenarios.} Beyond trajectory following, the learned residual control could be extended to more complex manipulation tasks involving object grasping, dynamic obstacle avoidance, and contact-rich interactions. The current framework provides a solid foundation that could be enriched with additional perception modalities (RGB-D cameras, force-torque sensors) and more sophisticated task specifications.

\section{Conclusion}

This work demonstrates that residual reinforcement learning offers a promising middle ground between classical motion planning and end-to-end learned control. By combining the safety and interpretability of traditional planners with the adaptability of deep RL, we achieve robust trajectory tracking under realistic perception noise and calibration errors—at least within simulation.

The strong validation results in Isaac Lab (>69\% error reduction) confirm the technical viability of the approach. However, the true test lies in physical deployment, which remains the natural continuation of this work. With proper safety protocols, cross-simulator validation, and iterative refinement, sim-to-real transfer is an achievable next step that would validate the practical utility of this hybrid architecture for real-world robotic manipulation.
