\section{Contexte}
L'essor de l'apprentissage par renforcement (RL) en robotique et la problématique du "Reality Gap" (l'écart entre simulation et réalité).

\section{Problématique}
Comment garantir un mouvement fluide et précis pour un UR10 en utilisant des données visuelles imparfaites ?

\section{Objectif}
Développer une approche de Residual Reinforcement Learning pour une tâche de reaching planaire (2D).

\section{Annonce du plan}
De la configuration logicielle à la validation Sim-to-Sim.
% - Chapter 2: System architecture (ROS2, Isaac Lab, PPO)
% - Chapter 3: Validation strategy (domain randomization tests)
% - Chapter 4: Experimental results
% - Chapter 5: Conclusion

